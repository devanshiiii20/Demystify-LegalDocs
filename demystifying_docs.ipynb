{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devanshiiii20/Demystify-LegalDocs/blob/main/demystifying_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kcedYWTcB63V"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-documentai google-cloud-aiplatform vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NcIPvteB7iB"
      },
      "outputs": [],
      "source": [
        "from google.cloud import documentai_v1 as documentai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "import vertexai\n",
        "from textwrap import wrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EseytB_ngiYm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Paths of files already uploaded in Colab Files section\n",
        "SERVICE_ACCOUNT_KEY_PATH = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "SAMPLE_DOC_PATH = \"/content/Non Disclosure Agreement.pdf\"\n",
        "\n",
        "# Set the environment variable for Google credentials\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n",
        "\n",
        "PROJECT_ID = \"demystifying-legal-docs\"\n",
        "LOCATION = \"us\"\n",
        "PROCESSOR_ID = \"cc201b11f66615f5\"\n",
        "\n",
        "print(\"‚úÖ Using JSON key:\", SERVICE_ACCOUNT_KEY_PATH)\n",
        "print(\"‚úÖ Using sample document:\", SAMPLE_DOC_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cpO5XdswZ9DV"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade streamlit google-cloud-documentai google-cloud-aiplatform vertexai pyngrok -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c_sVLYV8gZH-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path of JSON key already uploaded in Colab Files section\n",
        "SERVICE_ACCOUNT_KEY_PATH = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "\n",
        "# Set environment variable\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n",
        "\n",
        "print(\"‚úÖ Google Application Credentials set to:\", SERVICE_ACCOUNT_KEY_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dd7cbd9"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uPrVpNq8Z9hB"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "edcd33a1"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/demystifying_docs.py\n",
        "import os\n",
        "from google.cloud import documentai_v1 as documentai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "import vertexai\n",
        "from textwrap import wrap\n",
        "import time\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from google.api_core import exceptions\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Project info\n",
        "PROJECT_ID = \"demystifying-legal-docs\"\n",
        "LOCATION = \"us\"\n",
        "PROCESSOR_ID = \"cc201b11f66615f5\"\n",
        "VERTEX_AI_LOCATION = \"us-central1\"\n",
        "\n",
        "SERVICE_ACCOUNT_KEY_PATH = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_KEY_PATH)\n",
        "vertexai.init(project=PROJECT_ID, location=VERTEX_AI_LOCATION, credentials=credentials)\n",
        "\n",
        "def extract_text_from_document(content):\n",
        "    print(\"Starting text extraction from document...\")\n",
        "    client = documentai.DocumentProcessorServiceClient.from_service_account_file(\n",
        "        SERVICE_ACCOUNT_KEY_PATH\n",
        "    )\n",
        "    name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/processors/{PROCESSOR_ID}\"\n",
        "    raw_document = {\"content\": content, \"mime_type\": \"application/pdf\"}\n",
        "    request = {\"name\": name, \"raw_document\": raw_document}\n",
        "    response = client.process_document(request=request)\n",
        "    print(\"Text extraction completed.\")\n",
        "    return response.document.text\n",
        "\n",
        "def simplify_text(prompt, max_retries=5, initial_delay=1):\n",
        "    print(\"Starting text simplification...\")\n",
        "    model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "    generation_config = GenerationConfig(max_output_tokens=512)\n",
        "    delay = initial_delay\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            resp = model.generate_content(\n",
        "                f\"\"\"Summarize the following legal text in plain professional English.\n",
        "                RULES:\n",
        "                - Use only full sentences in paragraph form.\n",
        "                - Do not use bullets, numbering, stars, or markdown formatting.\n",
        "                - Do not use casual phrases like 'okay', 'let‚Äôs break this down', etc.\n",
        "                - Do not repeat the same information more than once.\n",
        "                - Keep it concise: no more than three short paragraphs.\n",
        "                - The style must be clear, formal and explanatory.\n",
        "\n",
        "                Text to simplify:\n",
        "                {prompt}\n",
        "                \"\"\",\n",
        "                generation_config=generation_config\n",
        "            )\n",
        "            print(\"Text simplification completed.\")\n",
        "            return resp.text.strip()\n",
        "        except exceptions.ResourceExhausted as e:\n",
        "            if i < max_retries - 1:\n",
        "                print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                print(f\"ResourceExhausted error: {e}. Max retries reached.\")\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2\n",
        "    return \"\"\n",
        "\n",
        "def simplify_long_text(text, chunk_size=800):\n",
        "    print(\"Starting long text simplification...\")\n",
        "    chunks = wrap(text, chunk_size)\n",
        "    parts = []\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        future_to_chunk = {executor.submit(simplify_text, chunk): i for i, chunk in enumerate(chunks)}\n",
        "        for future in as_completed(future_to_chunk):\n",
        "            index = future_to_chunk[future]\n",
        "            try:\n",
        "                simplified_chunk = future.result()\n",
        "                parts.append((index, simplified_chunk))\n",
        "                print(f\"Processed chunk {index+1}/{len(chunks)}...\")\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {index+1} generated an exception: {exc}')\n",
        "                parts.append((index, f\"Error processing chunk {index+1}\"))\n",
        "\n",
        "    parts.sort(key=lambda x: x[0])\n",
        "    return \" \".join([part[1] for part in parts])\n",
        "\n",
        "def explain_jargon(text, max_retries=5, initial_delay=1):\n",
        "    print(\"Starting jargon explanation...\")\n",
        "    model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "    generation_config = GenerationConfig(max_output_tokens=600)\n",
        "    delay = initial_delay\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "           You are a legal assistant.\n",
        "            Read the legal text below and explain every legal term or jargon in clear, simple English.\n",
        "\n",
        "            Rules:\n",
        "            - Do NOT use markdown or symbols like **, *, -, >, #.\n",
        "            - Present each explanation as a plain sentence or numbered item.\n",
        "            - Avoid repeating the same explanation.\n",
        "            - Be concise but clear.\n",
        "\n",
        "            Text:\n",
        "            {text}\n",
        "            \"\"\"\n",
        "            resp = model.generate_content(prompt, generation_config=generation_config)\n",
        "            cleaned = re.sub(r\"\\*+\", \"\", resp.text)\n",
        "            cleaned = re.sub(r\"#+\", \"\", cleaned)\n",
        "            cleaned = re.sub(r\"‚Ä¢\", \"-\", cleaned)\n",
        "            print(\"Jargon explanation completed.\")\n",
        "            return cleaned.strip()\n",
        "        except exceptions.ResourceExhausted as e:\n",
        "            if i < max_retries - 1:\n",
        "                print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                print(f\"ResourceExhausted error: {e}. Max retries reached.\")\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2\n",
        "    return \"\"\n",
        "\n",
        "def simplify_long_text_sequential(text, chunk_size=800, delay_between_chunks=5):\n",
        "    print(\"Starting sequential long text simplification...\")\n",
        "    chunks = wrap(text, chunk_size)\n",
        "    parts = []\n",
        "    for i, c in enumerate(chunks):\n",
        "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
        "        simplified_chunk = simplify_text(c)\n",
        "        parts.append(simplified_chunk)\n",
        "        time.sleep(delay_between_chunks)\n",
        "    return \" \".join(parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8e078beb"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "from demystifying_docs import extract_text_from_document, simplify_long_text, explain_jargon\n",
        "from google.cloud import translate_v2 as translate\n",
        "import base64, time\n",
        "import os\n",
        "\n",
        "# Paths for already uploaded files in Colab\n",
        "SERVICE_ACCOUNT_KEY_PATH = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "SAMPLE_DOC_PATH = \"/content/Non Disclosure Agreement.pdf\"\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n",
        "\n",
        "# PDF preview function\n",
        "def show_pdf(file_bytes):\n",
        "    base64_pdf = base64.b64encode(file_bytes).decode('utf-8')\n",
        "    pdf_display = f'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"100%\" height=\"600\" type=\"application/pdf\"></iframe>'\n",
        "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
        "\n",
        "# Translate text function\n",
        "def translate_text(text, target_language):\n",
        "    client = translate.Client.from_service_account_json(SERVICE_ACCOUNT_KEY_PATH)\n",
        "    lang_map = {\"English\": \"en\", \"Hindi\": \"hi\"}\n",
        "    if target_language == \"English\":\n",
        "        return text\n",
        "    result = client.translate(text, target_language=lang_map[target_language])\n",
        "    return result[\"translatedText\"]\n",
        "\n",
        "# Risk detection function\n",
        "def detect_risks(text):\n",
        "    risks = []\n",
        "    risk_keywords = {\n",
        "        \"Penalty / Late Fees\": [\"penalty\", \"late fee\", \"fine\"],\n",
        "        \"Termination / Lock-in\": [\"termination\", \"lock-in\", \"binding period\", \"expiry\"],\n",
        "        \"Payment / Interest\": [\"interest\", \"payment\", \"due\", \"loan\"],\n",
        "        \"Confidentiality\": [\"confidential\", \"non-disclosure\", \"nda\"],\n",
        "        \"Liability\": [\"liability\", \"indemnify\", \"responsible\"]\n",
        "    }\n",
        "    lowered = text.lower()\n",
        "    for category, keywords in risk_keywords.items():\n",
        "        for kw in keywords:\n",
        "            if kw in lowered:\n",
        "                risks.append(f\"‚ö†Ô∏è {category}: contains '{kw}'\")\n",
        "                break\n",
        "    return risks if risks else [\"‚úÖ No major risks detected.\"]\n",
        "\n",
        "# Streamlit UI setup\n",
        "st.set_page_config(\n",
        "    page_title=\"Demystify Legal Docs\",\n",
        "    page_icon=\"üìë\",\n",
        "    layout=\"wide\",\n",
        ")\n",
        "\n",
        "st.markdown(\"<p class='title'>üìë Demystify Legal Docs</p>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<p class='subtitle'>Upload your legal document and get a simplified version instantly.</p>\", unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar language selection\n",
        "language = st.sidebar.selectbox(\"üåç Choose output language\", [\"English\", \"Hindi\"])\n",
        "\n",
        "st.sidebar.title(\"‚ÑπÔ∏è About\")\n",
        "st.sidebar.info(\"Demystify Legal Docs is a GenAI-powered tool that makes legal language accessible. It extracts contracts and judgments using Document AI, simplifies them with Vertex AI, explains jargon in plain English, and highlights hidden risks. Built to bridge the gap between law and people, so everyone can make informed decisions.\\n\")\n",
        "\n",
        "# Use sample document directly\n",
        "use_sample = st.checkbox(\"üìÇ Try with Sample Document\")\n",
        "\n",
        "if use_sample:\n",
        "    with open(SAMPLE_DOC_PATH, \"rb\") as f:\n",
        "        file_bytes = f.read()\n",
        "else:\n",
        "    uploaded_pdf = st.file_uploader(\"üìÇ Upload a PDF\", type=\"pdf\")\n",
        "    file_bytes = uploaded_pdf.read() if uploaded_pdf else None\n",
        "\n",
        "if file_bytes:\n",
        "    st.write(\"Extracting text‚Ä¶\")\n",
        "    raw_text = extract_text_from_document(file_bytes)\n",
        "\n",
        "    tabs = st.tabs([\n",
        "        \"üìù Simplified Text\",\n",
        "        \"üìë Original PDF\",\n",
        "        \"üìò Legal Jargon Explained\",\n",
        "        \"üîç Summary\",\n",
        "        \"‚ö†Ô∏è Risks\"\n",
        "    ])\n",
        "\n",
        "    # Simplified Text tab\n",
        "    with tabs[0]:\n",
        "        with st.spinner(\"‚ö° Simplifying your document... Please wait.\"):\n",
        "            simplified = simplify_long_text(raw_text)\n",
        "        simplified_out = translate_text(simplified, language)\n",
        "        st.text_area(\"\", simplified_out, height=400)\n",
        "        st.download_button(\"‚ú® Download Simplified Doc\", data=simplified_out, file_name=\"simplified.txt\")\n",
        "\n",
        "    # Original PDF tab\n",
        "    with tabs[1]:\n",
        "        show_pdf(file_bytes)\n",
        "\n",
        "    # Legal Jargon Explained tab\n",
        "    with tabs[2]:\n",
        "        with st.spinner(\"üìò Explaining legal jargon...\"):\n",
        "            jargon_explained = explain_jargon(raw_text[:1500])\n",
        "        jargon_out = translate_text(jargon_explained, language)\n",
        "        st.text_area(\"\", jargon_out, height=400)\n",
        "        st.download_button(\"üìò Download Jargon Explanation\", data=jargon_out, file_name=\"jargon_explanation.txt\")\n",
        "\n",
        "    # Summary tab\n",
        "    with tabs[3]:\n",
        "        with st.spinner(\"üßæ Generating summary...\"):\n",
        "            time.sleep(5)\n",
        "            summary = simplify_long_text(\"Summarize this document in plain English:\\n\" + raw_text[:2000])\n",
        "        summary_out = translate_text(summary, language)\n",
        "        st.text_area(\"\", summary_out, height=250)\n",
        "        st.download_button(\"üîç Download Summary\", data=summary_out, file_name=\"summary.txt\")\n",
        "\n",
        "    # Risks tab\n",
        "    with tabs[4]:\n",
        "        with st.spinner(\"üîé Checking for risks...\"):\n",
        "            risks = detect_risks(raw_text)\n",
        "        for r in risks:\n",
        "            st.write(r)\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.markdown(\n",
        "    \"\"\"\n",
        "    <div class=\"sidebar-footer\">\n",
        "    üë©‚Äçüíª TEAM : AC/PC\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "adb1532b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/demystify\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "files_in_folder = os.listdir(folder_path)\n",
        "if files_in_folder:\n",
        "    print(f\"‚úÖ Files in '{folder_path}':\")\n",
        "    for file_name in files_in_folder:\n",
        "        print(f\" - {file_name}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è No files found in '{folder_path}'. You can upload files manually to this folder using the left sidebar uploader in Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fb30d871"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTHTOKEN = \"31haLAEOJZKFwD6QLriY5QTjjgZ_2ABAMCxWb3Hu1iFmaNvVL\"\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "print(\"‚úÖ ngrok authtoken set successfully. You won't need to enter it again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "repo_folder = \"/content/Demystify-LegalDocs\"\n",
        "os.makedirs(repo_folder, exist_ok=True)\n",
        "\n",
        "# Copy files\n",
        "shutil.copy(\"/content/app.py\", repo_folder)\n",
        "shutil.copy(\"/content/demystifying_docs.py\", repo_folder)\n",
        "\n",
        "# (optional) copy your sample doc\n",
        "if os.path.exists(\"/content/Non Disclosure Agreement.pdf\"):\n",
        "    shutil.copy(\"/content/Non Disclosure Agreement.pdf\", repo_folder)\n",
        "\n",
        "# (optional) copy JSON key (‚ö†Ô∏è only if you plan to .gitignore it later!)\n",
        "if os.path.exists(\"/content/demystifying-legal-docs-656e8c1f99a1.json\"):\n",
        "    shutil.copy(\"/content/demystifying-legal-docs-656e8c1f99a1.json\", repo_folder)\n",
        "\n",
        "print(\"‚úÖ All files copied to:\", repo_folder)"
      ],
      "metadata": {
        "id": "9TLXF853W5ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fce867db"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "ngrok.kill()\n",
        "time.sleep(2)\n",
        "\n",
        "# Paths for sample PDF and service account key\n",
        "source_pdf_path = \"/content/Non Disclosure Agreement.pdf\"\n",
        "source_key_path = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "\n",
        "if os.path.exists(source_pdf_path):\n",
        "    # destination_pdf_path = \"/content/Non Disclosure Agreement.pdf\" # This line caused the error\n",
        "    # shutil.copyfile(source_pdf_path, destination_pdf_path) # This line caused the error\n",
        "    print(f\"‚úÖ Sample document ready at {source_pdf_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Sample document not found at {source_pdf_path}. Upload it manually using the left sidebar in Colab.\")\n",
        "\n",
        "if os.path.exists(source_key_path):\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = source_key_path\n",
        "    print(f\"‚úÖ GOOGLE_APPLICATION_CREDENTIALS set to {source_key_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Service account key not found at {source_key_path}. Upload manually in Colab.\")\n",
        "\n",
        "# Set ngrok token\n",
        "NGROK_AUTHTOKEN = \"31haLAEOJZKFwD6QLriY5QTjjgZ_2ABAMCxWb3Hu1iFmaNvVL\"\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "# Connect ngrok to Streamlit port\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üöÄ Streamlit app is live at:\", public_url)\n",
        "\n",
        "# Kill any existing Streamlit processes\n",
        "subprocess.run([\"pkill\", \"streamlit\"])\n",
        "time.sleep(2)\n",
        "\n",
        "# Start Streamlit app in the background\n",
        "!streamlit run app.py --server.port 8501 &> /dev/null &"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLVzdjQWAbIIp0BzL5YPUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}