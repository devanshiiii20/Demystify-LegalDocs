{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devanshiiii20/Demystify-LegalDocs/blob/main/demystifying_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kcedYWTcB63V",
        "outputId": "140d0d79-beb5-471e-810c-aba3b4a588db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-documentai in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (1.71.1)\n",
            "Requirement already satisfied: vertexai in /usr/local/lib/python3.12/dist-packages (1.71.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-documentai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-documentai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-documentai) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (3.37.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.1.1)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.11.7)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-documentai google-cloud-aiplatform vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NcIPvteB7iB"
      },
      "outputs": [],
      "source": [
        "from google.cloud import documentai_v1 as documentai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "import vertexai\n",
        "from textwrap import wrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EseytB_ngiYm",
        "outputId": "c707e0f6-c9e3-42ac-9604-0e3f1ac53aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using JSON key: /content/demystifying-legal-docs-656e8c1f99a1.json\n",
            "‚úÖ Using sample document: /content/Non Disclosure Agreement.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Paths of files already uploaded in Colab Files section\n",
        "SERVICE_ACCOUNT_KEY_PATH = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "SAMPLE_DOC_PATH = \"/content/Non Disclosure Agreement.pdf\"\n",
        "\n",
        "# Set the environment variable for Google credentials\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n",
        "\n",
        "PROJECT_ID = \"demystifying-legal-docs\"\n",
        "LOCATION = \"us\"\n",
        "PROCESSOR_ID = \"cc201b11f66615f5\"\n",
        "\n",
        "print(\"‚úÖ Using JSON key:\", SERVICE_ACCOUNT_KEY_PATH)\n",
        "print(\"‚úÖ Using sample document:\", SAMPLE_DOC_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpO5XdswZ9DV",
        "outputId": "920817f5-d090-415a-be74-0cd4ca45e9d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade streamlit google-cloud-documentai google-cloud-aiplatform vertexai pyngrok -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c_sVLYV8gZH-",
        "outputId": "1dca24a2-aac5-4c83-a014-c260e5bf1369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Google Application Credentials set to: /content/demystifying-legal-docs-656e8c1f99a1.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path of JSON key already uploaded in Colab Files section\n",
        "SERVICE_ACCOUNT_KEY_PATH = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "\n",
        "# Set environment variable\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n",
        "\n",
        "print(\"‚úÖ Google Application Credentials set to:\", SERVICE_ACCOUNT_KEY_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1dd7cbd9"
      },
      "outputs": [],
      "source": [
        "!pip install PyMuPDF -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uPrVpNq8Z9hB",
        "outputId": "bcc13d89-5d56-4815-a799-bf35518dd27f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "edcd33a1",
        "outputId": "36a42b05-3258-40ba-aa28-3f734d717bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/demystifying_docs.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/demystifying_docs.py\n",
        "import os\n",
        "from google.cloud import documentai_v1 as documentai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "import vertexai\n",
        "from textwrap import wrap\n",
        "import time\n",
        "import re\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from google.api_core import exceptions\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Project info\n",
        "PROJECT_ID = \"demystifying-legal-docs\"\n",
        "LOCATION = \"us\"\n",
        "PROCESSOR_ID = \"cc201b11f66615f5\"\n",
        "VERTEX_AI_LOCATION = \"us-central1\"\n",
        "\n",
        "SERVICE_ACCOUNT_KEY_PATH = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_KEY_PATH)\n",
        "vertexai.init(project=PROJECT_ID, location=VERTEX_AI_LOCATION, credentials=credentials)\n",
        "\n",
        "def extract_text_from_document(content):\n",
        "    print(\"Starting text extraction from document...\")\n",
        "    client = documentai.DocumentProcessorServiceClient.from_service_account_file(\n",
        "        SERVICE_ACCOUNT_KEY_PATH\n",
        "    )\n",
        "    name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/processors/{PROCESSOR_ID}\"\n",
        "    raw_document = {\"content\": content, \"mime_type\": \"application/pdf\"}\n",
        "    request = {\"name\": name, \"raw_document\": raw_document}\n",
        "    response = client.process_document(request=request)\n",
        "    print(\"Text extraction completed.\")\n",
        "    return response.document.text\n",
        "\n",
        "def simplify_text(prompt, max_retries=5, initial_delay=1):\n",
        "    print(\"Starting text simplification...\")\n",
        "    model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "    generation_config = GenerationConfig(max_output_tokens=512)\n",
        "    delay = initial_delay\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            resp = model.generate_content(\n",
        "                f\"\"\"Summarize the following legal text in plain professional English.\n",
        "                RULES:\n",
        "                - Use only full sentences in paragraph form.\n",
        "                - Do not use bullets, numbering, stars, or markdown formatting.\n",
        "                - Do not use casual phrases like 'okay', 'let‚Äôs break this down', etc.\n",
        "                - Do not repeat the same information more than once.\n",
        "                - Keep it concise: no more than three short paragraphs.\n",
        "                - The style must be clear, formal and explanatory.\n",
        "\n",
        "                Text to simplify:\n",
        "                {prompt}\n",
        "                \"\"\",\n",
        "                generation_config=generation_config\n",
        "            )\n",
        "            print(\"Text simplification completed.\")\n",
        "            return resp.text.strip()\n",
        "        except exceptions.ResourceExhausted as e:\n",
        "            if i < max_retries - 1:\n",
        "                print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                print(f\"ResourceExhausted error: {e}. Max retries reached.\")\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2\n",
        "    return \"\"\n",
        "\n",
        "def simplify_long_text(text, chunk_size=800):\n",
        "    print(\"Starting long text simplification...\")\n",
        "    chunks = wrap(text, chunk_size)\n",
        "    parts = []\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        future_to_chunk = {executor.submit(simplify_text, chunk): i for i, chunk in enumerate(chunks)}\n",
        "        for future in as_completed(future_to_chunk):\n",
        "            index = future_to_chunk[future]\n",
        "            try:\n",
        "                simplified_chunk = future.result()\n",
        "                parts.append((index, simplified_chunk))\n",
        "                print(f\"Processed chunk {index+1}/{len(chunks)}...\")\n",
        "            except Exception as exc:\n",
        "                print(f'Chunk {index+1} generated an exception: {exc}')\n",
        "                parts.append((index, f\"Error processing chunk {index+1}\"))\n",
        "\n",
        "    parts.sort(key=lambda x: x[0])\n",
        "    return \" \".join([part[1] for part in parts])\n",
        "\n",
        "def explain_jargon(text, max_retries=5, initial_delay=1):\n",
        "    print(\"Starting jargon explanation...\")\n",
        "    model = GenerativeModel(\"gemini-2.0-flash-lite\")\n",
        "    generation_config = GenerationConfig(max_output_tokens=600)\n",
        "    delay = initial_delay\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "           You are a legal assistant.\n",
        "            Read the legal text below and explain every legal term or jargon in clear, simple English.\n",
        "\n",
        "            Rules:\n",
        "            - Do NOT use markdown or symbols like **, *, -, >, #.\n",
        "            - Present each explanation as a plain sentence or numbered item.\n",
        "            - Avoid repeating the same explanation.\n",
        "            - Be concise but clear.\n",
        "\n",
        "            Text:\n",
        "            {text}\n",
        "            \"\"\"\n",
        "            resp = model.generate_content(prompt, generation_config=generation_config)\n",
        "            cleaned = re.sub(r\"\\*+\", \"\", resp.text)\n",
        "            cleaned = re.sub(r\"#+\", \"\", cleaned)\n",
        "            cleaned = re.sub(r\"‚Ä¢\", \"-\", cleaned)\n",
        "            print(\"Jargon explanation completed.\")\n",
        "            return cleaned.strip()\n",
        "        except exceptions.ResourceExhausted as e:\n",
        "            if i < max_retries - 1:\n",
        "                print(f\"ResourceExhausted error: {e}. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                delay *= 2\n",
        "            else:\n",
        "                print(f\"ResourceExhausted error: {e}. Max retries reached.\")\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2\n",
        "    return \"\"\n",
        "\n",
        "def simplify_long_text_sequential(text, chunk_size=800, delay_between_chunks=5):\n",
        "    print(\"Starting sequential long text simplification...\")\n",
        "    chunks = wrap(text, chunk_size)\n",
        "    parts = []\n",
        "    for i, c in enumerate(chunks):\n",
        "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
        "        simplified_chunk = simplify_text(c)\n",
        "        parts.append(simplified_chunk)\n",
        "        time.sleep(delay_between_chunks)\n",
        "    return \" \".join(parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8e078beb",
        "outputId": "bc7a0a91-8117-483b-fa61-ec22d11d63ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-21 17:17:34.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.369 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.412 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.415 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-21 17:17:34.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from demystifying_docs import extract_text_from_document, simplify_long_text, explain_jargon\n",
        "from google.cloud import translate_v2 as translate\n",
        "import base64, time\n",
        "import os\n",
        "\n",
        "# Paths for already uploaded files in Colab\n",
        "SERVICE_ACCOUNT_KEY_PATH = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "SAMPLE_DOC_PATH = \"/content/Non Disclosure Agreement.pdf\"\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_KEY_PATH\n",
        "\n",
        "# PDF preview function\n",
        "def show_pdf(file_bytes):\n",
        "    base64_pdf = base64.b64encode(file_bytes).decode('utf-8')\n",
        "    pdf_display = f'<iframe src=\"data:application/pdf;base64,{base64_pdf}\" width=\"100%\" height=\"600\" type=\"application/pdf\"></iframe>'\n",
        "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
        "\n",
        "# Translate text function\n",
        "def translate_text(text, target_language):\n",
        "    client = translate.Client.from_service_account_json(SERVICE_ACCOUNT_KEY_PATH)\n",
        "    lang_map = {\"English\": \"en\", \"Hindi\": \"hi\"}\n",
        "    if target_language == \"English\":\n",
        "        return text\n",
        "    result = client.translate(text, target_language=lang_map[target_language])\n",
        "    return result[\"translatedText\"]\n",
        "\n",
        "# Risk detection function\n",
        "def detect_risks(text):\n",
        "    risks = []\n",
        "    risk_keywords = {\n",
        "        \"Penalty / Late Fees\": [\"penalty\", \"late fee\", \"fine\"],\n",
        "        \"Termination / Lock-in\": [\"termination\", \"lock-in\", \"binding period\", \"expiry\"],\n",
        "        \"Payment / Interest\": [\"interest\", \"payment\", \"due\", \"loan\"],\n",
        "        \"Confidentiality\": [\"confidential\", \"non-disclosure\", \"nda\"],\n",
        "        \"Liability\": [\"liability\", \"indemnify\", \"responsible\"]\n",
        "    }\n",
        "    lowered = text.lower()\n",
        "    for category, keywords in risk_keywords.items():\n",
        "        for kw in keywords:\n",
        "            if kw in lowered:\n",
        "                risks.append(f\"‚ö†Ô∏è {category}: contains '{kw}'\")\n",
        "                break\n",
        "    return risks if risks else [\"‚úÖ No major risks detected.\"]\n",
        "\n",
        "# Streamlit UI setup\n",
        "st.set_page_config(\n",
        "    page_title=\"Demystify Legal Docs\",\n",
        "    page_icon=\"üìë\",\n",
        "    layout=\"wide\",\n",
        ")\n",
        "\n",
        "st.markdown(\"<p class='title'>üìë Demystify Legal Docs</p>\", unsafe_allow_html=True)\n",
        "st.markdown(\"<p class='subtitle'>Upload your legal document and get a simplified version instantly.</p>\", unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar language selection\n",
        "language = st.sidebar.selectbox(\"üåç Choose output language\", [\"English\", \"Hindi\"])\n",
        "\n",
        "st.sidebar.title(\"‚ÑπÔ∏è About\")\n",
        "st.sidebar.info(\"Demystify Legal Docs is a GenAI-powered tool that makes legal language accessible. It extracts contracts and judgments using Document AI, simplifies them with Vertex AI, explains jargon in plain English, and highlights hidden risks. Built to bridge the gap between law and people, so everyone can make informed decisions.\\n\")\n",
        "\n",
        "# Use sample document directly\n",
        "use_sample = st.checkbox(\"üìÇ Try with Sample Document\")\n",
        "\n",
        "if use_sample:\n",
        "    with open(SAMPLE_DOC_PATH, \"rb\") as f:\n",
        "        file_bytes = f.read()\n",
        "else:\n",
        "    uploaded_pdf = st.file_uploader(\"üìÇ Upload a PDF\", type=\"pdf\")\n",
        "    file_bytes = uploaded_pdf.read() if uploaded_pdf else None\n",
        "\n",
        "if file_bytes:\n",
        "    st.write(\"Extracting text‚Ä¶\")\n",
        "    raw_text = extract_text_from_document(file_bytes)\n",
        "\n",
        "    tabs = st.tabs([\n",
        "        \"üìù Simplified Text\",\n",
        "        \"üìë Original PDF\",\n",
        "        \"üìò Legal Jargon Explained\",\n",
        "        \"üîç Summary\",\n",
        "        \"‚ö†Ô∏è Risks\"\n",
        "    ])\n",
        "\n",
        "    # Simplified Text tab\n",
        "    with tabs[0]:\n",
        "        with st.spinner(\"‚ö° Simplifying your document... Please wait.\"):\n",
        "            simplified = simplify_long_text(raw_text)\n",
        "        simplified_out = translate_text(simplified, language)\n",
        "        st.text_area(\"\", simplified_out, height=400)\n",
        "        st.download_button(\"‚ú® Download Simplified Doc\", data=simplified_out, file_name=\"simplified.txt\")\n",
        "\n",
        "    # Original PDF tab\n",
        "    with tabs[1]:\n",
        "        show_pdf(file_bytes)\n",
        "\n",
        "    # Legal Jargon Explained tab\n",
        "    with tabs[2]:\n",
        "        with st.spinner(\"üìò Explaining legal jargon...\"):\n",
        "            jargon_explained = explain_jargon(raw_text[:1500])\n",
        "        jargon_out = translate_text(jargon_explained, language)\n",
        "        st.text_area(\"\", jargon_out, height=400)\n",
        "        st.download_button(\"üìò Download Jargon Explanation\", data=jargon_out, file_name=\"jargon_explanation.txt\")\n",
        "\n",
        "    # Summary tab\n",
        "    with tabs[3]:\n",
        "        with st.spinner(\"üßæ Generating summary...\"):\n",
        "            time.sleep(5)\n",
        "            summary = simplify_long_text(\"Summarize this document in plain English:\\n\" + raw_text[:2000])\n",
        "        summary_out = translate_text(summary, language)\n",
        "        st.text_area(\"\", summary_out, height=250)\n",
        "        st.download_button(\"üîç Download Summary\", data=summary_out, file_name=\"summary.txt\")\n",
        "\n",
        "    # Risks tab\n",
        "    with tabs[4]:\n",
        "        with st.spinner(\"üîé Checking for risks...\"):\n",
        "            risks = detect_risks(raw_text)\n",
        "        for r in risks:\n",
        "            st.write(r)\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "st.sidebar.markdown(\n",
        "    \"\"\"\n",
        "    <div class=\"sidebar-footer\">\n",
        "    üë©‚Äçüíª TEAM : AC/PC\n",
        "    </div>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "adb1532b",
        "outputId": "8a9fa61b-46ce-4964-f82e-083abbc01a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è No files found in '/content/demystify'. You can upload files manually to this folder using the left sidebar uploader in Colab.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = \"/content/demystify\"\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "files_in_folder = os.listdir(folder_path)\n",
        "if files_in_folder:\n",
        "    print(f\"‚úÖ Files in '{folder_path}':\")\n",
        "    for file_name in files_in_folder:\n",
        "        print(f\" - {file_name}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è No files found in '{folder_path}'. You can upload files manually to this folder using the left sidebar uploader in Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fb30d871",
        "outputId": "842985ba-aef4-40e9-a1b6-0fbecea3a7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ngrok authtoken set successfully. You won't need to enter it again.\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "NGROK_AUTHTOKEN = \"31haLAEOJZKFwD6QLriY5QTjjgZ_2ABAMCxWb3Hu1iFmaNvVL\"\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "print(\"‚úÖ ngrok authtoken set successfully. You won't need to enter it again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fce867db"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "ngrok.kill()\n",
        "time.sleep(2)\n",
        "\n",
        "# Paths for sample PDF and service account key\n",
        "source_pdf_path = \"/content/Non Disclosure Agreement.pdf\"\n",
        "source_key_path = \"/content/demystifying-legal-docs-656e8c1f99a1.json\"\n",
        "\n",
        "if os.path.exists(source_pdf_path):\n",
        "    # destination_pdf_path = \"/content/Non Disclosure Agreement.pdf\" # This line caused the error\n",
        "    # shutil.copyfile(source_pdf_path, destination_pdf_path) # This line caused the error\n",
        "    print(f\"‚úÖ Sample document ready at {source_pdf_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Sample document not found at {source_pdf_path}. Upload it manually using the left sidebar in Colab.\")\n",
        "\n",
        "if os.path.exists(source_key_path):\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = source_key_path\n",
        "    print(f\"‚úÖ GOOGLE_APPLICATION_CREDENTIALS set to {source_key_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Service account key not found at {source_key_path}. Upload manually in Colab.\")\n",
        "\n",
        "# Set ngrok token\n",
        "NGROK_AUTHTOKEN = \"31haLAEOJZKFwD6QLriY5QTjjgZ_2ABAMCxWb3Hu1iFmaNvVL\"\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "# Connect ngrok to Streamlit port\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üöÄ Streamlit app is live at:\", public_url)\n",
        "\n",
        "# Kill any existing Streamlit processes\n",
        "subprocess.run([\"pkill\", \"streamlit\"])\n",
        "time.sleep(2)\n",
        "\n",
        "# Start Streamlit app in the background\n",
        "!streamlit run app.py --server.port 8501 &> /dev/null &"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyMM2o+8gWv/gnFuM8KR0xKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}